{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn import utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, GlobalMaxPooling1D, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the clean tweets csv obtained from cleanTweets microservice\n",
    "#Volume mapping for microservice- TBD;\n",
    "\n",
    "csv = \"./resources/clean_tweets.csv\"\n",
    "df = pd.read_csv(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()  #No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input as tweets and output as sentiment\n",
    "x = df.tweets    \n",
    "y = df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "863"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, high=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, test and validation\n",
    "\n",
    "x_train, x_val_test, y_train, y_val_test = \\\n",
    "    train_test_split(x, y, test_size=0.02, random_state=np.random.randint(0, high=1000))\n",
    "\n",
    "x_test, x_val, y_test, y_val = \\\n",
    "    train_test_split(x_val_test, y_val_test, test_size=0.5, random_state=np.random.randint(0, high=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0] + x_test.shape[0] + x_val.shape[0] == x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0] + y_test.shape[0] + y_val.shape[0] == y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2Vec: CBOW or Skip Gram \n",
    "#CBOW: Predict a word from surrounding context\n",
    "#Skip Gram: Predict surrounding context from a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596251/1596251 [00:06<00:00, 250250.14it/s]\n"
     ]
    }
   ],
   "source": [
    "#Word2Vec unigram - CBOW model\n",
    "\n",
    "cores = multiprocessing.cpu_count()  #no. of cpu threads\n",
    "model_ug_cbow = Word2Vec(sg=0, workers=cores/2, min_count=2, size=200) #skip-gram=0\n",
    "model_ug_cbow.build_vocab([x.split() for x in tqdm(df.tweets)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596251/1596251 [00:06<00:00, 264914.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15791624, 20613984)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_cbow.train(utils.shuffle([x.split() for x in tqdm(df.tweets)]), total_examples=len(df.tweets), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596251/1596251 [00:05<00:00, 266357.61it/s]\n"
     ]
    }
   ],
   "source": [
    "#Word2Vec Unigram - Skip Gram Model\n",
    "model_ug_sg = Word2Vec(sg=1, workers=cores/2)\n",
    "model_ug_sg.build_vocab([x.split() for x in tqdm(df.tweets)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596251/1596251 [00:05<00:00, 269881.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15633668, 20613984)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_sg.train(utils.shuffle([x.split() for x in tqdm(df.tweets)]), total_examples=len(df.tweets), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 106460 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#Create Word Embeddings for Keras model\n",
    "\n",
    "embeddings_index = {}\n",
    "for w in model_ug_cbow.wv.vocab.keys():\n",
    "    embeddings_index[w] = model_ug_cbow.wv[w] #np.append(model_ug_cbow.wv[w],model_ug_sg.wv[w])\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=100000)\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1564325, 45)\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "x_train_seq = pad_sequences(sequences, maxlen=45)\n",
    "print('Shape of data tensor:', x_train_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_val = tokenizer.texts_to_sequences(x_val)\n",
    "x_val_seq = pad_sequences(sequences_val, maxlen=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 100000\n",
    "embedding_matrix = np.zeros((num_words, 200))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/botman/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/botman/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/botman/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 1564325 samples, validate on 15963 samples\n",
      "Epoch 1/5\n",
      " - 317s - loss: 0.4466 - acc: 0.7893 - val_loss: 0.4344 - val_acc: 0.7969\n",
      "Epoch 2/5\n",
      " - 317s - loss: 0.4256 - acc: 0.8022 - val_loss: 0.4218 - val_acc: 0.8034\n",
      "Epoch 3/5\n",
      " - 313s - loss: 0.4189 - acc: 0.8061 - val_loss: 0.4231 - val_acc: 0.8044\n",
      "Epoch 4/5\n",
      " - 318s - loss: 0.4147 - acc: 0.8087 - val_loss: 0.4148 - val_acc: 0.8102\n",
      "Epoch 5/5\n",
      " - 318s - loss: 0.4120 - acc: 0.8102 - val_loss: 0.4139 - val_acc: 0.8119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd2a827e10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Keras model with 1D Conv-NN\n",
    "\n",
    "\n",
    "embedd = Embedding(100000, 200, weights=[embedding_matrix], input_length=45, trainable=False)\n",
    "model = Sequential()\n",
    "model.add(embedd)\n",
    "model.add(Conv1D(filters=100, kernel_size=2, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_val), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"keras-word2vec-twitter-sentiment\"\n",
    "model.save(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
