{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from kafka import KafkaConsumer\n",
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "#Here we are using Stanford's Sentiment140 dataset, that has 1.6 million tweets and their sentiment\n",
    "\n",
    "cols = ['sentiment', 'id', 'date', 'query', 'user', 'tweet']\n",
    "pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "df = pd.read_csv(\"../resources/training.1600000.processed.noemoticon.csv\", \n",
    "                        header=None, \n",
    "                        names=cols,\n",
    "                        encoding=\"latin-1\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 is negative sentiment and 1 is positive\n",
    "df['sentiment'] = df['sentiment'].map({0: 0, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811592</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mybirch</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811594</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>coZZ</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811795</td>\n",
       "      <td>Mon Apr 06 22:20:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>2Hood4Hollywood</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812025</td>\n",
       "      <td>Mon Apr 06 22:20:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mimismo</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date     query  \\\n",
       "0  0          1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1  0          1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2  0          1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3  0          1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4  0          1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "5  0          1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "6  0          1467811592  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "7  0          1467811594  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "8  0          1467811795  Mon Apr 06 22:20:05 PDT 2009  NO_QUERY   \n",
       "9  0          1467812025  Mon Apr 06 22:20:09 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user  \\\n",
       "0  _TheSpecialOne_   \n",
       "1  scotthamilton     \n",
       "2  mattycus          \n",
       "3  ElleCTF           \n",
       "4  Karoli            \n",
       "5  joy_wolf          \n",
       "6  mybirch           \n",
       "7  coZZ              \n",
       "8  2Hood4Hollywood   \n",
       "9  mimismo           \n",
       "\n",
       "                                                                                                                 tweet  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "1  is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!      \n",
       "2  @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                            \n",
       "3  my whole body feels itchy and like its on fire                                                                       \n",
       "4  @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.       \n",
       "5  @Kwesidei not the whole crew                                                                                         \n",
       "6  Need a hug                                                                                                           \n",
       "7  @LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?                  \n",
       "8  @Tatiana_K nope they didn't have it                                                                                  \n",
       "9  @twittera que me muera ?                                                                                             "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking out the dataset\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only take relevant columns\n",
    "train = df[['sentiment', 'tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0  0           \n",
       "1  0           \n",
       "2  0           \n",
       "3  0           \n",
       "4  0           \n",
       "5  0           \n",
       "6  0           \n",
       "7  0           \n",
       "8  0           \n",
       "9  0           \n",
       "\n",
       "                                                                                                                 tweet  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "1  is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!      \n",
       "2  @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                            \n",
       "3  my whole body feels itchy and like its on fire                                                                       \n",
       "4  @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.       \n",
       "5  @Kwesidei not the whole crew                                                                                         \n",
       "6  Need a hug                                                                                                           \n",
       "7  @LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?                  \n",
       "8  @Tatiana_K nope they didn't have it                                                                                  \n",
       "9  @twittera que me muera ?                                                                                             "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/botman/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/botman/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#With pre-clean-len we can check if all tweets are 140 characters or less\n",
    "train.loc[:, \"pre-clean-len\"] = [len(t) for t in train.tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train[\"pre-clean-len\"]>140].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing usernames\n",
    "text = bs(train.tweet[343], 'lxml').get_text()\n",
    "re.sub(r'@[A-Za-z0-9]+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing URLs\n",
    "text = bs(train.tweet[0], 'lxml').get_text()\n",
    "re.sub('https?://[A-Za-z0-9./]+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing any unparsable character in unicode\n",
    "text = train['tweet'][226].encode('latin-1').decode('utf-8')\n",
    "text.replace(\"�\", \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tweet[175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep text only\n",
    "text = train.tweet[175]\n",
    "re.sub(\"[^a-zA-Z]\", \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "pat3 = r'www.[^ ]+'\n",
    "combined_pat = r'|'.join((pat1, pat2, pat3))\n",
    "neg_dict = {\"isn't\":\"is not\", \"wasn't\":\"was not\", \"aren't\":\"are not\", \"weren't\":\"were not\", \"haven't\":\"have not\", \n",
    "            \"hasn't\":\"has not\", \"hadn't\":\"had not\", \"won't\":\"will not\", \"shalln't\":\"shall not\",\n",
    "            \"don't\":\"do not\", \"doesn't\":\"does not\", \"didn't\":\"did not\", \"shouldn't\":\"should not\",\n",
    "            \"wouldn't\":\"would not\", \"couldn't\":\"could not\", \"mightn't\":\"might not\", \n",
    "            \"musn't\":\"must not\"}\n",
    "\n",
    "neg_pat = re.compile(r\"\\b(\" + \"|\".join(neg_dict.keys()) + r\")/b\")\n",
    "\n",
    "\n",
    "#Clean text - only text remains ; remove URLs, contractions, usernames\n",
    "def clean(text):\n",
    "    soup = bs(text, 'lxml').get_text()0\n",
    "    try:\n",
    "        bom_removed = soup.encode('latin-1').decode('utf-8-sig').replace(\"�\", \"?\")\n",
    "    except:\n",
    "        #Don't know, why this exception comes ? - TBD;\n",
    "        bom_removed = soup \n",
    "    stripped_pat = re.sub(combined_pat, '', bom_removed).lower()\n",
    "    stripped_neg = neg_pat.sub(lambda x: neg_dict[x.group()], stripped_pat)\n",
    "    stripped_text = re.sub('[^a-zA-Z]', ' ', stripped_neg)\n",
    "    words = tok.tokenize(stripped_text)\n",
    "    words = \" \".join(words).strip()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cleaned_tweets = []\n",
    "\n",
    "#Clean the training dataset\n",
    "def clean_tweets(df):\n",
    "    pbar = tqdm(range(0,len(df)))\n",
    "    for i in pbar:\n",
    "        #if ((i+1)%10000 == 0):\n",
    "        #    print(\"Tweets %d out of %d have been processed\" %(i+1, len(df)))\n",
    "        cleaned_tweets.append(clean(df['tweet'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Using threads to clean the training data\n",
    "from _thread import start_new_thread\n",
    "\n",
    "num = [0, 400000, 800000, 120000, 160000]\n",
    "cleaned_tweets = []\n",
    "\n",
    "\n",
    "def clean_tweets_list(i):\n",
    "    for i in range(num[i], num[i+1]):\n",
    "        if ((i+1)%10000 == 0):\n",
    "            print(\"Tweets %d out of %d have been processed\" %(i+1, num[1]))\n",
    "        cleaned_tweets.append(clean(train['tweet'][i]))\n",
    "        \n",
    "start_new_thread(clean_tweets_list, (0,))\n",
    "start_new_thread(clean_tweets_list, (1,))\n",
    "start_new_thread(clean_tweets_list, (2,))\n",
    "start_new_thread(clean_tweets_list, (3,))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset of cleaned tweet text,and its sentiment \n",
    "clean_tweets_df = pd.DataFrame(cleaned_tweets, columns=['tweets'])\n",
    "clean_tweets_df['sentiment'] = df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets_df['tweets'][208]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_tweets_df[clean_tweets_df.isnull().any(axis=1)]\n",
    "clean_tweets_df[clean_tweets_df['tweets']==\"\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[208]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for blank tweets, then drop them\n",
    "blank_tweets = clean_tweets_df[clean_tweets_df['tweets']==\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets_df.drop(blank_tweets.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NaN\n",
    "clean_tweets_df.dropna(inplace=True)\n",
    "clean_tweets_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to csv \n",
    "clean_tweets_df.to_csv(\"clean_tweets.csv\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "#Send this csv to analyseTweets with Kafka -TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    consumer_records = KafkaConsumer(in_topic)\n",
    "    producer = KafkaProducer(bootstrap_servers=broker)\n",
    "    for in_msg in consumer_records:\n",
    "        out_msg = clean(in_msg)\n",
    "        producer.send(out_topic, out_msg.encode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
